{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "04a6086cc9014d96a87ea4339765e998",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "This notebook demonstrates some of the basic functionality of librosa version 0.3.\n",
    "\n",
    "Following through this example, you'll learn how to:\n",
    "\n",
    "* Load audio input\n",
    "* Compute mel spectrogram, MFCC, delta features, chroma\n",
    "* Locate beat events\n",
    "* Compute beat-synchronous features\n",
    "* Display features\n",
    "* Save beat tracker output to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "ac10e96753f242529bb286b9d755935b",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We'll need the os module for file path manipulation\n",
    "import os\n",
    "\n",
    "# And numpy for some mathematical operations\n",
    "import numpy as np\n",
    "\n",
    "# Librosa for audio\n",
    "import librosa\n",
    "\n",
    "# matplotlib for displaying the output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# and IPython.display for audio output\n",
    "import IPython.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "77db6ae90c58461ba9f58dbc8549faf2",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# audio_path = librosa.util.example_audio_file()\n",
    "audio_path = librosa.example('vibeace', hq=True)\n",
    "# audio_path = '/tmp/host/test.opus'\n",
    "\n",
    "# or uncomment the line below and point it at your favorite song:\n",
    "#\n",
    "# audio_path = '/path/to/your/favorite/song.mp3'\n",
    "\n",
    "y, sr = librosa.load(audio_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9b07c52a7db94a69b85724d62c3afb69",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "By default, librosa will resample the signal to 22050Hz.\n",
    "\n",
    "You can change this behavior by setting the `sr` parameter of `librosa.load()`, or disable resampling entirely by setting `sr=None`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "7375c58943eb41f09b757d1bacf3a096",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "###Warning\n",
    "\n",
    "You might want to stop here to verify that [scikits.samplerate](https://pypi.python.org/pypi/scikits.samplerate/0.3.3) is installed and functioning correctly.  Without this, audio resampling will fall back on `scipy.signal.resample()`, which is rather inefficient.\n",
    "\n",
    "You can test this by printing out the `librosa.core._HAS_SAMPLERATE` flag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "4147f7daa5174d3288d3ff7c189e07fd",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "No librosa.core attribute _HAS_SAMPLERATE",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHAS_SAMPLERATE: \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_HAS_SAMPLERATE\u001b[49m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lazy_loader/__init__.py:88\u001b[0m, in \u001b[0;36mattach.<locals>.__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attr\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: No librosa.core attribute _HAS_SAMPLERATE"
     ]
    }
   ],
   "source": [
    "print('HAS_SAMPLERATE: ', librosa.core._HAS_SAMPLERATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "82cad927d7b843c59fee3648c625f0c2",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# Mel spectrogram\n",
    "This first step will show how to compute a [Mel](http://en.wikipedia.org/wiki/Mel_scale) spectrogram from an audio waveform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "199acf6da7bf4fe091f507067fdb7ed4",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "No librosa attribute logamplitude",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m S \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mmelspectrogram(y\u001b[38;5;241m=\u001b[39my, sr\u001b[38;5;241m=\u001b[39msr, n_fft\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2048\u001b[39m, hop_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, n_mels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Convert to log scale (dB). We'll use the peak power as reference.\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m log_S \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogamplitude\u001b[49m(S, ref_power\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mmax)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Make a new figure\u001b[39;00m\n\u001b[1;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m,\u001b[38;5;241m4\u001b[39m))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lazy_loader/__init__.py:88\u001b[0m, in \u001b[0;36mattach.<locals>.__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attr\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: No librosa attribute logamplitude"
     ]
    }
   ],
   "source": [
    "# Let's make and display a mel-scaled power (energy-squared) spectrogram\n",
    "# We use a small hop length of 64 here so that the frames line up with the beat tracker example below.\n",
    "S = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=64, n_mels=128)\n",
    "\n",
    "# Convert to log scale (dB). We'll use the peak power as reference.\n",
    "log_S = librosa.logamplitude(S, ref_power=np.max)\n",
    "\n",
    "# Make a new figure\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "# Display the spectrogram on a mel scale\n",
    "# sample rate and hop length parameters are used to render the time axis\n",
    "librosa.display.specshow(log_S, sr=sr, hop_length=64, x_axis='time', y_axis='mel')\n",
    "\n",
    "# Put a descriptive title on the plot\n",
    "plt.title('mel power spectrogram')\n",
    "\n",
    "# draw a color bar\n",
    "plt.colorbar(format='%+02.0f dB')\n",
    "\n",
    "# Make the figure layout compact\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "52751f420f494c43a2d16dd959b9b133",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# Harmonic-percussive source separate\n",
    "\n",
    "Before doing any signal analysis, let's pull apart the harmonic and percussive components of the audio.  This is pretty easy to do with the `effects` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "d212edf6a2a544c8be75d70712abdd54",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "y_harmonic, y_percussive = librosa.effects.hpss(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "e22e0d0fe3134e6fa2a5fbc2fb05dfdd",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# What do the spectrograms look like?\n",
    "# Let's make and display a mel-scaled power (energy-squared) spectrogram\n",
    "# We use a small hop length of 64 here so that the frames line up with the beat tracker example below.\n",
    "S_harmonic   = librosa.feature.melspectrogram(y_harmonic, sr=sr, n_fft=2048, hop_length=64, n_mels=128)\n",
    "S_percussive = librosa.feature.melspectrogram(y_percussive, sr=sr, n_fft=2048, hop_length=64, n_mels=128)\n",
    "\n",
    "# Convert to log scale (dB). We'll use the peak power as reference.\n",
    "log_Sh = librosa.logamplitude(S_harmonic, ref_power=np.max)\n",
    "log_Sp = librosa.logamplitude(S_percussive, ref_power=np.max)\n",
    "\n",
    "# Make a new figure\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "# Display the spectrogram on a mel scale\n",
    "librosa.display.specshow(log_Sh, y_axis='mel')\n",
    "\n",
    "# Put a descriptive title on the plot\n",
    "plt.title('mel power spectrogram (Harmonic)')\n",
    "\n",
    "# draw a color bar\n",
    "plt.colorbar(format='%+02.0f dB')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "librosa.display.specshow(log_Sp, sr=sr, hop_length=64, x_axis='time', y_axis='mel')\n",
    "\n",
    "# Put a descriptive title on the plot\n",
    "plt.title('mel power spectrogram (Percussive)')\n",
    "\n",
    "# draw a color bar\n",
    "plt.colorbar(format='%+02.0f dB')\n",
    "\n",
    "# Make the figure layout compact\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "59b0d9d02be840ce9e2a73335a250969",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# Chromagram\n",
    "\n",
    "Next, we'll extract [Chroma](http://en.wikipedia.org/wiki/Pitch_class) features to represent pitch information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "8495eb4a1bc64dc095fa0c5cfeaf9976",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# We'll use a longer FFT window here to better resolve low frequencies\n",
    "# We'll use the harmonic component to avoid pollution from transients\n",
    "C = librosa.feature.chromagram(y=y_harmonic, sr=sr, n_fft=4096, hop_length=64)\n",
    "\n",
    "# Make a new figure\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "# Display the chromagram: the energy in each chromatic pitch class as a function of time\n",
    "# To make sure that the colors span the full range of chroma values, set vmin and vmax\n",
    "librosa.display.specshow(C, sr=sr, hop_length=64, x_axis='time', y_axis='chroma', vmin=0, vmax=1)\n",
    "\n",
    "plt.title('Chromagram')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "65922d06c8514a4bbcef7afb1acadbca",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# MFCC\n",
    "\n",
    "[Mel-frequency cepstral coefficients](http://en.wikipedia.org/wiki/Mel-frequency_cepstrum) are commonly used to represent texture or timbre of sound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "cba3a45f6c42411ead4c3eb29e0361bb",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# Next, we'll extract the top 20 Mel-frequency cepstral coefficients (MFCCs)\n",
    "mfcc        = librosa.feature.mfcc(S=log_S, n_mfcc=20)\n",
    "\n",
    "# Let's pad on the first and second deltas while we're at it\n",
    "delta_mfcc  = librosa.feature.delta(mfcc)\n",
    "delta2_mfcc = librosa.feature.delta(mfcc, order=2)\n",
    "\n",
    "# How do they look?  We'll show each in its own subplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(3,1,1)\n",
    "librosa.display.specshow(mfcc)\n",
    "plt.ylabel('MFCC')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(3,1,2)\n",
    "librosa.display.specshow(delta_mfcc)\n",
    "plt.ylabel('MFCC-$\\Delta$')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(3,1,3)\n",
    "librosa.display.specshow(delta2_mfcc, sr=sr, hop_length=64, x_axis='time')\n",
    "plt.ylabel('MFCC-$\\Delta^2$')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# For future use, we'll stack these together into one matrix\n",
    "M = np.vstack([mfcc, delta_mfcc, delta2_mfcc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "7f56ae99fad64b3fbf8422f2c8537be8",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# About color maps...\n",
    "\n",
    "In the above examples, Mel power spectrogram is negative-valued (dB relative to peak power), and `specshow()` defaults to a purple->white color gradient.\n",
    "\n",
    "The chromagram example is positive-valued, and `specshow()` will default to a white->red color gradient.\n",
    "\n",
    "If the input data has both positive and negative values, as in the MFCC example, then a purple->white->orange diverging color gradient will be used.\n",
    "\n",
    "These defaults have been selected to ensure readability in print (grayscale) and are color-blind friendly.\n",
    "\n",
    "Just as in `pyplot.imshow()`, the color map can be overriden by setting the `cmap` keyword argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "572a88a219ac46ed8c6f7640ed2f0e09",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# Beat tracking\n",
    "\n",
    "The beat tracker returns an estimate of the tempo (in beats per minute) and frame identifiers of beat events.\n",
    "\n",
    "The input can be either an audio time series (as we do below), or an onset strength envelope as calculated by `librosa.onset.onset_strength()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "26454d04154e4cef95b086f688d37bd8",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# Now, let's run the beat tracker\n",
    "# We'll use the percussive component for this part\n",
    "tempo, beats = librosa.beat.beat_track(y=y_percussive, sr=sr, hop_length=64)\n",
    "\n",
    "# Let's re-draw the spectrogram, but this time, overlay the detected beats\n",
    "plt.figure(figsize=(12,4))\n",
    "librosa.display.specshow(log_S, sr=sr, hop_length=64, x_axis='time', y_axis='mel')\n",
    "\n",
    "# Let's draw lines with a drop shadow on the beat events\n",
    "plt.vlines(beats, 0, log_S.shape[0], colors='k', linestyles='-', linewidth=2.5)\n",
    "plt.vlines(beats, 0, log_S.shape[0], colors='w', linestyles='-', linewidth=1.5)\n",
    "plt.axis('tight')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "2e4ebf857d6b432a81b808ccf3c53d50",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "By default, the beat tracker will trim away any leading or trailing beats that don't appear strong enough.  \n",
    "\n",
    "To disable this behavior, call `beat_track()` with `trim=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "c652f507ca5c4a23abdfd82dd5153e40",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "print 'Estimated tempo:        %.2f BPM' % tempo\n",
    "\n",
    "print 'First 5 beat frames:   ', beats[:5]\n",
    "\n",
    "# Frame numbers are great and all, but when do those beats occur?\n",
    "print 'First 5 beat times:    ', librosa.frames_to_time(beats[:5], sr=sr, hop_length=64)\n",
    "\n",
    "# We could also get frame numbers from times by librosa.time_to_frames()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "592c30f1d7d4423998f0cc096721e0ca",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# Beat-synchronous feature aggregation\n",
    "\n",
    "Once we've located the beat events, we can use them to summarize the feature content of each beat.\n",
    "\n",
    "This can be useful for reducing data dimensionality, and removing transient noise from the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "db57bbd119314979932e5c6eee529cc3",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# feature.sync will summarize each beat event by the mean feature vector within that beat\n",
    "\n",
    "M_sync = librosa.feature.sync(M, beats)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "# Let's plot the original and beat-synchronous features against each other\n",
    "plt.subplot(2,1,1)\n",
    "librosa.display.specshow(M)\n",
    "plt.title('MFCC-$\\Delta$-$\\Delta^2$')\n",
    "\n",
    "# We can also use pyplot *ticks directly\n",
    "# Let's mark off the raw MFCC and the delta features\n",
    "plt.yticks(np.arange(0, M.shape[0], 20), ['MFCC', '$\\Delta$', '$\\Delta^2$'])\n",
    "\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "librosa.display.specshow(M_sync)\n",
    "\n",
    "# librosa can generate axis ticks from arbitrary timestamps and beat events also\n",
    "librosa.display.time_ticks(librosa.frames_to_time(beats, sr=sr, hop_length=64))\n",
    "\n",
    "plt.yticks(np.arange(0, M_sync.shape[0], 20), ['MFCC', '$\\Delta$', '$\\Delta^2$'])             \n",
    "plt.title('Beat-synchronous MFCC-$\\Delta$-$\\Delta^2$')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": "c38597d61aeb411d8f17d60d73cbaf49",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# Beat synchronization is flexible.\n",
    "# Instead of computing the mean delta-MFCC within each beat, let's do beat-synchronous chroma\n",
    "# We can replace the mean with any statistical aggregation function, such as min, max, or median.\n",
    "\n",
    "C_sync = librosa.feature.sync(C, beats, aggregate=np.median)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "librosa.display.specshow(C, sr=sr, hop_length=64, y_axis='chroma', vmin=0.0, vmax=1.0)\n",
    "plt.title('Chroma')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "librosa.display.specshow(C_sync, y_axis='chroma', vmin=0.0, vmax=1.0)\n",
    "\n",
    "beat_times = librosa.frames_to_time(beats, sr=sr, hop_length=64)\n",
    "librosa.display.time_ticks(beat_times)\n",
    "\n",
    "plt.title('Beat-synchronous Chroma (median aggregation)')\n",
    "\n",
    "plt.colorbar()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=f92cd40c-4eaf-409c-ba4b-6ea473d7b0d4' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "ba086ac821b94cdb8eeb97b36a30e405",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
